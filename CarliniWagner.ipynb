{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2iDhUE0OQJj"
      },
      "source": [
        "### Set UP\n",
        "* Robustbench: this library is used for loading robust classifer, For more information visit: https://github.com/RobustBench/robustbench\n",
        "\n",
        "* foolbox: this library is used for adversarial example generation. For more information visit: https://github.com/bethgelab/foolbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-XG3NmQI8aF"
      },
      "outputs": [],
      "source": [
        "from robustbench.utils import clean_accuracy\n",
        "from robustbench.utils import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import unique\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiKA1t-QOzlJ"
      },
      "source": [
        "### Download and preprocess the data:\n",
        "\n",
        "* We will use 1000 test examples from the cifar 10 dataset. These images are new to the model as it hasn't seen them in the training phase. We want to fool the model on its predictions for new images!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "XFuubfX3G6Ul",
        "outputId": "3ecf9b0f-5328-4b15-b705-98442a98e16d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A5gQCE0bHZhBlfcLQ2fFP5UygpgVkdAX\n",
            "To: /content/cifar10.pt\n",
            "100%|██████████| 12.3M/12.3M [00:00<00:00, 36.0MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cifar10.pt'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gdown\n",
        "output_file = 'cifar10.pt'\n",
        "file_id = \"1A5gQCE0bHZhBlfcLQ2fFP5UygpgVkdAX\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HPgPWYFJLHa",
        "outputId": "daa17c1e-05a8-41e3-c0bd-9c6a2dab7d09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-28-b0f49031be72>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  cifar_data = torch.load('cifar10.pt')\n"
          ]
        }
      ],
      "source": [
        "cifar_data = torch.load('cifar10.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D32wiSfHJHy",
        "outputId": "c3201e4f-3fdf-4b18-ab76-83ae4174198f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([100, 100, 100, 100, 100, 100, 100, 100, 100, 100]))\n"
          ]
        }
      ],
      "source": [
        "# Extract the images and labels tensors\n",
        "x_test = cifar_data['images'] / 255.0\n",
        "y_test = cifar_data['labels']\n",
        "\n",
        "print(unique(y_test, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xp3JY6QJPuD",
        "outputId": "1121eff3-3503-4bb7-8719-28d59c285cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 3, 32, 32]) torch.Size([1000])\n",
            "tensor(1.) tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "print(x_test.shape, y_test.shape)\n",
        "print(torch.max(x_test), torch.min(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiHHpdfePSr1"
      },
      "source": [
        "### Loading the robust model\n",
        "\n",
        "* IMPORTANT: You shouldn't change this part of the code as your final generated examples will be evaluated how successful you are at fooling this model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZEph6jWJQKz",
        "outputId": "1a2b6dcd-320d-41d0-97d8-a83c98f400dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/robustbench/utils.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n"
          ]
        }
      ],
      "source": [
        "model = load_model(model_name='Kireev2021Effectiveness_RLATAugMix', dataset='cifar10', threat_model='corruptions')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUF3TMgfPzgu"
      },
      "source": [
        "### GPU Utilization\n",
        "\n",
        "* For shorter running time, let's utilize GPU!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FTfa9zuJQH0",
        "outputId": "e52756bf-30f7-4b2f-d908-70a799727f63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available and set the device accordingly\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "model = model.to(device)\n",
        "x_test = x_test.to(device)\n",
        "y_test = y_test.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czWsx4ePQIkw"
      },
      "source": [
        "### Adversarial Example Generation -- Adversarial Perturbation\n",
        "\n",
        "* Here for a baseline, we use the PGD algorithm from foolbox library. This is the most important part of the challenge. What algorithm is gonna work best?\n",
        "\n",
        "* There are many algorithms and many other adversarial example generation algorithms. Don't forget to check out other libraries!\n",
        "\n",
        "  * One other very popular library among many others is Adversarial Robustness Toolbox (ART)!\n",
        "  * There are many more algorithms out there, your task is to find the ones that works best based on our evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0nS_MDuPxri"
      },
      "outputs": [],
      "source": [
        "model_fb = fb.PyTorchModel(model, bounds=(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdA5xLBJQSEV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fgPnoO_iyxM",
        "outputId": "52bf4ff0-b1c2-4b45-f31c-db02742d1df9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Carlini & Wagner with params: confidence=0, steps=1000, binary_search_steps=9, stepsize=0.1, initial_const=0.1, epsilon=None\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import foolbox as fb\n",
        "\n",
        "#carlini wagner\n",
        "confidence_grid = [0]\n",
        "cw_steps_grid = [1000]\n",
        "binary_search_steps = [9]\n",
        "stepsize = [0.1]\n",
        "initial_const = [0.1]\n",
        "epsilon_grid = [None]\n",
        "\n",
        "# Combine all hyperparameters into a grid for both attacks\n",
        "cw_grid = list(itertools.product(confidence_grid, cw_steps_grid, binary_search_steps, stepsize, initial_const, epsilon_grid))\n",
        "\n",
        "# Function to run the Carlini & Wagner attack\n",
        "def run_cw(model_fb, x_test, y_test, binary_search_steps, confidence, steps, step_size, initial_const, epsilon):\n",
        "    # Initialize the C&W attack\n",
        "    attack = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=binary_search_steps, steps=steps, stepsize=step_size , confidence=confidence, initial_const=initial_const)\n",
        "    # Call the attack without a fixed epsilon (uses L2 norm minimization)\n",
        "    return attack(model_fb, x_test, y_test,epsilons=epsilon)\n",
        "\n",
        "# Iterate through both attack grids\n",
        "results = []\n",
        "\n",
        "# Carlini & Wagner grid search\n",
        "for params in cw_grid:\n",
        "    confidence, cw_step, binary_search_step, step_size, initial_const, epsilon = params\n",
        "    print(f\"Running Carlini & Wagner with params: confidence={confidence}, steps={cw_step}, binary_search_steps={binary_search_step}, stepsize={step_size}, initial_const={initial_const}, epsilon={epsilon}\")\n",
        "\n",
        "    # Run the C&W attack with current parameters\n",
        "    _, advs, success = run_cw(model_fb, x_test, y_test, binary_search_step, confidence,  cw_step, step_size, initial_const, epsilon)\n",
        "\n",
        "    # Evaluate based on your custom scoring system\n",
        "    score = 1 - success.float().mean()\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        'attack': 'CW',\n",
        "        'confidence': confidence,\n",
        "        'steps': cw_step,\n",
        "        'binary_search_steps': binary_search_step,\n",
        "        'stepsize': step_size,\n",
        "        'initial_const': initial_const,\n",
        "        'score': score\n",
        "    })\n",
        "    print(f\"Carlini & Wagner Score: {score}\")\n",
        "\n",
        "# After completing both grid searches, find the best set of parameters based on the score\n",
        "best_result = max(results, key=lambda x: x['score'])\n",
        "print(f\"Best result: {best_result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxeMMZ-gRzzR"
      },
      "source": [
        "### Let's compare the accuracies before and after perturbation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY92YmusJee2",
        "outputId": "8d613ed3-1361-42b0-a329-ad371e459c8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Robust accuracy: 1.7%\n",
            "0.941\n"
          ]
        }
      ],
      "source": [
        "print('Robust accuracy: {:.1%}'.format(1 - success.float().mean()))\n",
        "print(clean_accuracy(model, x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAGYD88bR73n"
      },
      "source": [
        "### Let's explore how our perturbations look!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-wa0RC_OBxs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Pass the perturbed images through the model to get the predicted labels\n",
        "with torch.no_grad():  # No need to track gradients during inference\n",
        "    logits_adv = model(advs[0].to('cuda'))  # Get the logits for the adversarial examples\n",
        "\n",
        "# Get the predicted labels from the logits\n",
        "predicted_labels_adv = torch.argmax(logits_adv, dim=1)\n",
        "\n",
        "# Find which examples were misclassified (where predicted label != true label)\n",
        "misclassified_indices = (predicted_labels_adv != y_test.to('cuda')).nonzero(as_tuple=True)[0]\n",
        "\n",
        "# Get the misclassified original and perturbed images, true labels, and incorrect labels\n",
        "misclassified_images = advs[0][misclassified_indices]\n",
        "misclassified_original_images = x_test.to('cuda')[misclassified_indices]\n",
        "misclassified_predicted_labels = predicted_labels_adv[misclassified_indices]\n",
        "misclassified_true_labels = y_test.to('cuda')[misclassified_indices]\n",
        "\n",
        "# Choose a random subset of misclassified images to display\n",
        "num_images_to_show = min(10, len(misclassified_images))  # Limit to 10 images for display\n",
        "random_indices = random.sample(range(len(misclassified_images)), num_images_to_show)\n",
        "\n",
        "# Class names (assuming CIFAR-10)\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Plot the original and misclassified perturbed images side by side\n",
        "plt.figure(figsize=(25, 5))\n",
        "for i, idx in enumerate(random_indices):\n",
        "    # Original image\n",
        "    original_image = misclassified_original_images[idx]\n",
        "    true_label = misclassified_true_labels[idx].item()\n",
        "\n",
        "    # Perturbed image\n",
        "    perturbed_image = misclassified_images[idx]\n",
        "    incorrect_label = misclassified_predicted_labels[idx].item()\n",
        "\n",
        "    # Convert images from tensor to numpy and transpose from (C, H, W) to (H, W, C)\n",
        "    original_img = original_image.permute(1, 2, 0).cpu().numpy()\n",
        "    perturbed_img = perturbed_image.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    # Plot original image\n",
        "    plt.subplot(2, num_images_to_show, i+1)\n",
        "    plt.imshow(original_img, interpolation='none')\n",
        "    plt.title(f\"Original: {class_names[true_label]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Plot perturbed (misclassified) image\n",
        "    plt.subplot(2, num_images_to_show, num_images_to_show + i + 1)\n",
        "    plt.imshow(perturbed_img, interpolation='none')\n",
        "    plt.title(f\"Perturbed: {class_names[incorrect_label]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgEqeBozSBvG"
      },
      "source": [
        "### Finally!\n",
        "\n",
        "* Let's save our perturbed samples in a folder called 'challenge' and submit them for the evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3gPVt_AOMb4",
        "outputId": "3a3ac58f-71d8-4f84-e68c-2ddae3cddefb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "advs = [advs]\n",
        "print(advs[0].shape)\n",
        "\n",
        "# Create the 'challenge' directory if it doesn't exist\n",
        "os.makedirs('challenge', exist_ok=True)\n",
        "\n",
        "# Path to save the adversarial examples\n",
        "file_path = os.path.join('challenge', 'advs.pkl')\n",
        "\n",
        "# Save the 'advs' object\n",
        "with open(file_path, 'wb') as f:\n",
        "    pickle.dump(advs, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVNnjEZnSQ4b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
