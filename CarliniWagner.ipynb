{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2iDhUE0OQJj"
      },
      "source": [
        "### Set UP\n",
        "* Robustbench: this library is used for loading robust classifer, For more information visit: https://github.com/RobustBench/robustbench\n",
        "\n",
        "* foolbox: this library is used for adversarial example generation. For more information visit: https://github.com/bethgelab/foolbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V-XG3NmQI8aF"
      },
      "outputs": [],
      "source": [
        "from robustbench.utils import clean_accuracy\n",
        "from robustbench.utils import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import unique\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiKA1t-QOzlJ"
      },
      "source": [
        "### Download and preprocess the data:\n",
        "\n",
        "* We will use 1000 test examples from the cifar 10 dataset. These images are new to the model as it hasn't seen them in the training phase. We want to fool the model on its predictions for new images!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "XFuubfX3G6Ul",
        "outputId": "3ecf9b0f-5328-4b15-b705-98442a98e16d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A5gQCE0bHZhBlfcLQ2fFP5UygpgVkdAX\n",
            "To: c:\\Users\\Elyas\\OneDrive - The University of Colorado Denver\\Desktop\\Projects\\decoy_challenge\\cifar10.pt\n",
            "100%|██████████| 12.3M/12.3M [00:00<00:00, 17.5MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'cifar10.pt'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gdown\n",
        "output_file = 'cifar10.pt'\n",
        "file_id = \"1A5gQCE0bHZhBlfcLQ2fFP5UygpgVkdAX\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HPgPWYFJLHa",
        "outputId": "daa17c1e-05a8-41e3-c0bd-9c6a2dab7d09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Elyas\\AppData\\Local\\Temp\\ipykernel_34044\\3968093994.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  cifar_data = torch.load('cifar10.pt')\n"
          ]
        }
      ],
      "source": [
        "cifar_data = torch.load('cifar10.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D32wiSfHJHy",
        "outputId": "c3201e4f-3fdf-4b18-ab76-83ae4174198f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([100, 100, 100, 100, 100, 100, 100, 100, 100, 100]))\n"
          ]
        }
      ],
      "source": [
        "# Extract the images and labels tensors\n",
        "x_test = cifar_data['images'] / 255.0\n",
        "y_test = cifar_data['labels']\n",
        "orig_x_test = x_test\n",
        "\n",
        "print(unique(y_test, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xp3JY6QJPuD",
        "outputId": "1121eff3-3503-4bb7-8719-28d59c285cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 3, 32, 32]) torch.Size([1000])\n",
            "tensor(1.) tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "print(x_test.shape, y_test.shape)\n",
        "print(torch.max(x_test), torch.min(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiHHpdfePSr1"
      },
      "source": [
        "### Loading the robust model\n",
        "\n",
        "* IMPORTANT: You shouldn't change this part of the code as your final generated examples will be evaluated how successful you are at fooling this model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZEph6jWJQKz",
        "outputId": "1a2b6dcd-320d-41d0-97d8-a83c98f400dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Elyas\\anaconda3\\envs\\Machinelearning\\Lib\\site-packages\\robustbench\\utils.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n"
          ]
        }
      ],
      "source": [
        "model = load_model(model_name='Kireev2021Effectiveness_RLATAugMix', dataset='cifar10', threat_model='corruptions')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUF3TMgfPzgu"
      },
      "source": [
        "### GPU Utilization\n",
        "\n",
        "* For shorter running time, let's utilize GPU!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FTfa9zuJQH0",
        "outputId": "e52756bf-30f7-4b2f-d908-70a799727f63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU: NVIDIA GeForce RTX 3090\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available and set the device accordingly\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "model = model.to(device)\n",
        "x_test = x_test.to(device)\n",
        "y_test = y_test.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czWsx4ePQIkw"
      },
      "source": [
        "### Adversarial Example Generation -- Adversarial Perturbation\n",
        "\n",
        "* Here for a baseline, we use the PGD algorithm from foolbox library. This is the most important part of the challenge. What algorithm is gonna work best?\n",
        "\n",
        "* There are many algorithms and many other adversarial example generation algorithms. Don't forget to check out other libraries!\n",
        "\n",
        "  * One other very popular library among many others is Adversarial Robustness Toolbox (ART)!\n",
        "  * There are many more algorithms out there, your task is to find the ones that works best based on our evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g0nS_MDuPxri"
      },
      "outputs": [],
      "source": [
        "model_fb = fb.PyTorchModel(model, bounds=(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Carlini & Wagner with params: confidence=0, steps=30, binary_search_steps=9, stepsize=0.001, initial_const=0.1, epsilon=None\n",
            "tensor([False, False,  True, False,  True,  True,  True, False, False,  True,\n",
            "        False, False,  True, False,  True, False, False,  True,  True, False,\n",
            "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "        False, False, False,  True, False, False, False,  True, False,  True,\n",
            "        False,  True, False,  True,  True, False,  True,  True, False, False,\n",
            "        False, False,  True, False, False,  True,  True,  True,  True,  True,\n",
            "         True, False, False, False, False, False, False,  True, False,  True,\n",
            "        False, False,  True, False,  True,  True,  True,  True,  True, False,\n",
            "        False,  True,  True,  True, False,  True,  True, False,  True, False,\n",
            "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "       device='cuda:0')\n",
            "Average Confidence Incorrect: 0.502372682094574, Confidence Gap: 0.46266278624534607, Perturbation Magnitude: 14.067753791809082, Score: 0.04599994421005249\n",
            "Best result: {'attack': 'CW', 'confidence': 0, 'steps': 30, 'binary_search_steps': 9, 'stepsize': 0.001, 'initial_const': 0.1, 'confidence_gap': 0.46266278624534607, 'avg_confidence_incorrect': 0.502372682094574}\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import foolbox as fb\n",
        "import itertools\n",
        "\n",
        "# Carlini Wagner hyperparameters\n",
        "confidence_grid = [0]  # Adjust this to vary the attack confidence\n",
        "cw_steps_grid = [2000]  # Number of steps for the attack\n",
        "binary_search_steps = [9]  # Binary search steps for C&W attack\n",
        "stepsize = [0.001]  # Step size for each attack iteration\n",
        "initial_const = [0.1]  # Initial constant for C&W attack\n",
        "epsilon_grid = [None]  # C&W doesn't rely on a fixed epsilon\n",
        "\n",
        "# Combine all hyperparameters into a grid\n",
        "cw_grid = list(itertools.product(confidence_grid, cw_steps_grid, binary_search_steps, stepsize, initial_const, epsilon_grid))\n",
        "\n",
        "# Function to get confidence of predictions\n",
        "def get_confidence(logits, labels):\n",
        "    # Apply softmax to convert logits to probabilities\n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "\n",
        "    # Get the confidence of the predicted class\n",
        "    predicted_confidences, predicted_classes = probabilities.max(dim=-1)\n",
        "\n",
        "    # Return the confidence for each prediction\n",
        "    return predicted_confidences\n",
        "\n",
        "# Function to run the Carlini & Wagner attack and calculate confidence\n",
        "def run_cw(model_fb, x_test, y_test, binary_search_steps, confidence, steps, step_size, initial_const, epsilon):\n",
        "    # Initialize the C&W attack\n",
        "    attack = fb.attacks.L2CarliniWagnerAttack(\n",
        "        binary_search_steps=binary_search_steps,\n",
        "        steps=steps,\n",
        "        stepsize=step_size,\n",
        "        confidence=confidence,\n",
        "        initial_const=initial_const\n",
        "    )\n",
        "\n",
        "\n",
        "    # Run the attack\n",
        "    _, advs, success = attack(model_fb, x_test, y_test, epsilons=epsilon)\n",
        "\n",
        "    return advs, success\n",
        "\n",
        "# Iterate through the attack hyperparameter grid\n",
        "results = []\n",
        "\n",
        "# Carlini & Wagner grid search\n",
        "for params in cw_grid:\n",
        "    confidence, cw_step, binary_search_step, step_size, initial_const, epsilon = params\n",
        "    print(f\"Running Carlini & Wagner with params: confidence={confidence}, steps={cw_step}, binary_search_steps={binary_search_step}, stepsize={step_size}, initial_const={initial_const}, epsilon={epsilon}\")\n",
        "\n",
        "    # Run the C&W attack with current parameters\n",
        "    advs, success = run_cw(model_fb, x_test, y_test, binary_search_step, confidence, cw_step, step_size, initial_const, epsilon)\n",
        "    print(success)\n",
        "    \n",
        "    # Evaluate on the clean test data to get clean confidences\n",
        "    clean_logits = model_fb(x_test)\n",
        "    clean_confidences = get_confidence(clean_logits, y_test)\n",
        "\n",
        "    # Evaluate on the adversarial examples to get adversarial confidences\n",
        "    adv_logits = model_fb(advs)\n",
        "    adv_confidences = get_confidence(adv_logits, y_test)\n",
        "\n",
        "    # Get confidence of incorrect adversarial predictions\n",
        "    incorrect_mask = success.bool()\n",
        "    incorrect_confidence = adv_confidences[incorrect_mask].mean().item()  # Average confidence for incorrect predictions\n",
        "\n",
        "    # Calculate confidence gap (difference between clean and adversarial confidences)\n",
        "    confidence_gap = (clean_confidences[incorrect_mask] - adv_confidences[incorrect_mask]).mean().item()\n",
        "\n",
        "    # Calculate the perturbation magnitude (L2 norm between original and adversarial examples)\n",
        "    perturbation_magnitude = torch.norm(advs - x_test, p=2, dim=(1, 2, 3)).mean().item()\n",
        "\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        'attack': 'CW',\n",
        "        'confidence': confidence,\n",
        "        'steps': cw_step,\n",
        "        'binary_search_steps': binary_search_step,\n",
        "        'stepsize': step_size,\n",
        "        'initial_const': initial_const,\n",
        "        'confidence_gap': confidence_gap,\n",
        "        'avg_confidence_incorrect': incorrect_confidence,\n",
        "    })\n",
        "    print(f\"Average Confidence Incorrect: {incorrect_confidence}, Confidence Gap: {confidence_gap}, Perturbation Magnitude: {perturbation_magnitude}, Score: {1 - success.float().mean()}\")\n",
        "\n",
        "# After completing both grid searches, find the best set of parameters based on confidence and confidence gap\n",
        "best_result = max(results, key=lambda x: x['avg_confidence_incorrect'])\n",
        "print(f\"Best result: {best_result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxeMMZ-gRzzR"
      },
      "source": [
        "### Let's compare the accuracies before and after perturbation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY92YmusJee2",
        "outputId": "8d613ed3-1361-42b0-a329-ad371e459c8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Robust accuracy: 4.6%\n",
            "0.941\n"
          ]
        }
      ],
      "source": [
        "print('Robust accuracy: {:.1%}'.format(1 - success.float().mean()))\n",
        "print(clean_accuracy(model, x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Perturbation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3gPVt_AOMb4",
        "outputId": "3a3ac58f-71d8-4f84-e68c-2ddae3cddefb"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'shape'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m advs \u001b[38;5;241m=\u001b[39m [advs]\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43madvs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create the 'challenge' directory if it doesn't exist\u001b[39;00m\n\u001b[0;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchallenge\u001b[39m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "advs = [advs]\n",
        "print(advs[0].shape)\n",
        "\n",
        "# Create the 'challenge' directory if it doesn't exist\n",
        "os.makedirs('challenge', exist_ok=True)\n",
        "\n",
        "# Path to save the adversarial examples\n",
        "file_path = os.path.join('challenge', 'advs.pkl')\n",
        "\n",
        "# Save the 'advs' object\n",
        "with open(file_path, 'wb') as f:\n",
        "    pickle.dump(advs, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load pkl model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eVNnjEZnSQ4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 3, 32, 32])\n",
            "Robust accuracy: 4.6%\n",
            "0.941\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "filename = 'challenge/CW230058.pkl'\n",
        "\n",
        "with open(filename, 'rb') as file:\n",
        "    data = pickle.load(file)\n",
        "    print(data[0].shape)\n",
        "    \n",
        "print('Robust accuracy: {:.1%}'.format(1 - success.float().mean()))\n",
        "print(clean_accuracy(model, x_test, y_test))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
