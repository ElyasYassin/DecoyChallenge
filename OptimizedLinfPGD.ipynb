{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElyasYassin/DecoyChallenge/blob/main/OptimizedLinfPGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2iDhUE0OQJj"
      },
      "source": [
        "### Set UP\n",
        "* Robustbench: this library is used for loading robust classifer, For more information visit: https://github.com/RobustBench/robustbench\n",
        "\n",
        "* foolbox: this library is used for adversarial example generation. For more information visit: https://github.com/bethgelab/foolbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qPZQUpV4J-oL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/RobustBench/robustbench.git # library for loading robust classifer\n",
        "!pip install -q foolbox # library for adversarial example generation\n",
        "!pip install timm==1.0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSA6ejlGe6Px",
        "outputId": "548906fb-8a69-4291-ae75-1798efd392b5"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(timm\u001b[38;5;241m.\u001b[39m__version__)\n",
            "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\Machinelearning\\Lib\\site-packages\\timm\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_scriptable, is_exportable, set_scriptable, set_exportable\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_model, list_models, list_pretrained, is_model, list_modules, model_entrypoint, \\\n\u001b[0;32m      4\u001b[0m     is_model_pretrained, get_pretrained_cfg, get_pretrained_cfg_value\n",
            "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\Machinelearning\\Lib\\site-packages\\timm\\layers\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madaptive_avgmax_pool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \\\n\u001b[0;32m      3\u001b[0m     adaptive_avgmax_pool2d, select_adaptive_pool2d, AdaptiveAvgMaxPool2d, SelectAdaptivePool2d\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention2d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiQueryAttention2d, Attention2d, MultiQueryAttentionV2\n",
            "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\Machinelearning\\Lib\\site-packages\\timm\\layers\\activations.py:9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" Activations\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mA collection of activations fn and modules with a common interface so that they can\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mHacked together by / Copyright 2020 Ross Wightman\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn \u001b[38;5;28;01mas\u001b[39;00m nn\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n",
            "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\Machinelearning\\Lib\\site-packages\\torch\\__init__.py:2476\u001b[0m\n\u001b[0;32m   2472\u001b[0m     torch_module_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;18m__name__\u001b[39m, device_type])\n\u001b[0;32m   2473\u001b[0m     sys\u001b[38;5;241m.\u001b[39mmodules[torch_module_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m-> 2476\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m   2477\u001b[0m     export \u001b[38;5;28;01mas\u001b[39;00m export,\n\u001b[0;32m   2478\u001b[0m     func \u001b[38;5;28;01mas\u001b[39;00m func,\n\u001b[0;32m   2479\u001b[0m     library \u001b[38;5;28;01mas\u001b[39;00m library,\n\u001b[0;32m   2480\u001b[0m     return_types \u001b[38;5;28;01mas\u001b[39;00m return_types,\n\u001b[0;32m   2481\u001b[0m )\n\u001b[0;32m   2482\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cond \u001b[38;5;28;01mas\u001b[39;00m cond, while_loop \u001b[38;5;28;01mas\u001b[39;00m while_loop\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vmap \u001b[38;5;28;01mas\u001b[39;00m vmap\n",
            "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\Machinelearning\\Lib\\site-packages\\torch\\export\\__init__.py:64\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrictMinMaxConstraint\n\u001b[0;32m     44\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstraint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDim\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnflattenedModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     61\u001b[0m ]\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_shapes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Constraint, Dim, dims, ShapesCollection\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexported_program\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram, ModuleCallEntry, ModuleCallSignature\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_signature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExportBackwardSignature, ExportGraphSignature\n",
            "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\Machinelearning\\Lib\\site-packages\\torch\\export\\dynamic_shapes.py:23\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     _get_node_type,\n\u001b[0;32m     13\u001b[0m     BUILTIN_TYPES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     tree_map_with_path,\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexported_program\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Symbol\n",
            "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\Machinelearning\\Lib\\site-packages\\torch\\export\\exported_program.py:26\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m contextmanager\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     Any,\n\u001b[0;32m     14\u001b[0m     Callable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     Union,\n\u001b[0;32m     24\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograd_not_implemented\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_library\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_class_registry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeScriptObject\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m first_call_function_nn_module_stack\n",
            "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\Machinelearning\\Lib\\site-packages\\torch\\_higher_order_ops\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcond\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cond\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     flex_attention,\n\u001b[0;32m      4\u001b[0m     flex_attention_backward,\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhints_wrap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hints_wrapper\n",
            "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\Machinelearning\\Lib\\site-packages\\torch\\_higher_order_ops\\cond.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional_tensor\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpytree\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DispatchKey\n",
            "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\Machinelearning\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, ContextManager, Dict, List, Optional, Tuple, Union\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01minductor_config\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpytree\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _functionalization_reapply_views_tls \u001b[38;5;28;01mas\u001b[39;00m _reapply_views\n",
            "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\Machinelearning\\Lib\\site-packages\\torch\\_inductor\\config.py:44\u001b[0m\n\u001b[0;32m     40\u001b[0m verbose_progress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# use fx aot graph codegen cache\u001b[39;00m\n\u001b[0;32m     43\u001b[0m fx_graph_cache \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 44\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCHINDUCTOR_FX_GRAPH_CACHE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_fbcode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     45\u001b[0m )\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# use remote fx aot graph codegen cache\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# False: Disables the cache\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# True: Enables the cache\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# None: Not set -- Off for OSS, JustKnobs based for internal\u001b[39;00m\n\u001b[0;32m     51\u001b[0m fx_graph_remote_cache: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m fx_graph_remote_cache_default()\n",
            "File \u001b[1;32mc:\\Users\\Elyas\\anaconda3\\envs\\Machinelearning\\Lib\\site-packages\\torch\\_inductor\\config.py:9\u001b[0m, in \u001b[0;36mis_fbcode\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_fbcode\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgit_version\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "import timm\n",
        "print(timm.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V-XG3NmQI8aF"
      },
      "outputs": [],
      "source": [
        "from robustbench.utils import clean_accuracy\n",
        "from robustbench.utils import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import unique\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiKA1t-QOzlJ"
      },
      "source": [
        "### Download and preprocess the data:\n",
        "\n",
        "* We will use 1000 test examples from the cifar 10 dataset. These images are new to the model as it hasn't seen them in the training phase. We want to fool the model on its predictions for new images!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "XFuubfX3G6Ul",
        "outputId": "41a53041-24cc-44c2-ff93-680765cfb78a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A5gQCE0bHZhBlfcLQ2fFP5UygpgVkdAX\n",
            "To: /content/cifar10.pt\n",
            "100%|██████████| 12.3M/12.3M [00:00<00:00, 22.0MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cifar10.pt'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gdown\n",
        "output_file = 'cifar10.pt'\n",
        "file_id = \"1A5gQCE0bHZhBlfcLQ2fFP5UygpgVkdAX\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HPgPWYFJLHa",
        "outputId": "acfff3eb-e861-4a99-de1a-230094120142"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-b0f49031be72>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  cifar_data = torch.load('cifar10.pt')\n"
          ]
        }
      ],
      "source": [
        "cifar_data = torch.load('cifar10.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D32wiSfHJHy",
        "outputId": "32e4304a-2bcf-4b7f-8a9a-b8938ecc4ed3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([100, 100, 100, 100, 100, 100, 100, 100, 100, 100]))\n"
          ]
        }
      ],
      "source": [
        "# Extract the images and labels tensors\n",
        "x_test = cifar_data['images'] / 255.0\n",
        "y_test = cifar_data['labels']\n",
        "\n",
        "print(unique(y_test, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xp3JY6QJPuD",
        "outputId": "5d637182-f92a-4621-abff-dd8316fb83e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 3, 32, 32]) torch.Size([1000])\n",
            "tensor(1.) tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "print(x_test.shape, y_test.shape)\n",
        "print(torch.max(x_test), torch.min(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiHHpdfePSr1"
      },
      "source": [
        "### Loading the robust model\n",
        "\n",
        "* IMPORTANT: You shouldn't change this part of the code as your final generated examples will be evaluated how successful you are at fooling this model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZEph6jWJQKz",
        "outputId": "14a34a1d-bbee-49eb-9387-d7ee59293137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading models/cifar10/corruptions/Kireev2021Effectiveness_RLATAugMix.pt (gdrive_id=19HNTdqJiuNyqFqIarPejniJEjZ3RQ_nj).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=19HNTdqJiuNyqFqIarPejniJEjZ3RQ_nj\n",
            "From (redirected): https://drive.google.com/uc?id=19HNTdqJiuNyqFqIarPejniJEjZ3RQ_nj&confirm=t&uuid=eb31fde4-e60d-4ffe-ae44-88266743779e\n",
            "To: /content/models/cifar10/corruptions/Kireev2021Effectiveness_RLATAugMix.pt\n",
            "100%|██████████| 89.5M/89.5M [00:02<00:00, 30.5MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/robustbench/utils.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n"
          ]
        }
      ],
      "source": [
        "import robustbench.utils\n",
        "model = load_model(model_name='Kireev2021Effectiveness_RLATAugMix', dataset='cifar10', threat_model='corruptions')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUF3TMgfPzgu"
      },
      "source": [
        "### GPU Utilization\n",
        "\n",
        "* For shorter running time, let's utilize GPU!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FTfa9zuJQH0",
        "outputId": "1f9967d5-d7e6-4336-b8b2-f9f661d5f2c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available and set the device accordingly\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "model = model.to(device)\n",
        "x_test = x_test.to(device)\n",
        "y_test = y_test.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czWsx4ePQIkw"
      },
      "source": [
        "### Adversarial Example Generation -- Adversarial Perturbation\n",
        "\n",
        "* Here for a baseline, we use the PGD algorithm from foolbox library. This is the most important part of the challenge. What algorithm is gonna work best?\n",
        "\n",
        "* There are many algorithms and many other adversarial example generation algorithms. Don't forget to check out other libraries!\n",
        "\n",
        "  * One other very popular library among many others is Adversarial Robustness Toolbox (ART)!\n",
        "  * There are many more algorithms out there, your task is to find the ones that works best based on our evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g0nS_MDuPxri"
      },
      "outputs": [],
      "source": [
        "model_fb = fb.PyTorchModel(model, bounds=(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eWP3A6Cqm7Xe"
      },
      "outputs": [],
      "source": [
        "_, advs, success = fb.attacks.LinfPGD(rel_stepsize=0.527, steps=10)(model_fb, x_test, y_test, epsilons=[8/255])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du34tCWUrhEo",
        "outputId": "fb5f8667-44c0-4b07-ac2c-97249f1b17e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running attack with params: rel_stepsize=0.527, steps=20, epsilon:0.054901960784313725\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'model_fb' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning attack with params: rel_stepsize=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrel_stepsize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, steps=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, epsilon:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilons_grid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Run the attack with current parameters\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m _, advs, success \u001b[38;5;241m=\u001b[39m run_attack(\u001b[43mmodel_fb\u001b[49m, x_test, y_test,\n\u001b[0;32m     24\u001b[0m                               rel_stepsize\u001b[38;5;241m=\u001b[39mrel_stepsize,\n\u001b[0;32m     25\u001b[0m                               steps\u001b[38;5;241m=\u001b[39msteps,\n\u001b[0;32m     26\u001b[0m                               epsilons\u001b[38;5;241m=\u001b[39mepsilons_grid)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Evaluate based on your custom scoring system (update this according to your project)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m success\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model_fb' is not defined"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import foolbox as fb\n",
        "\n",
        "# Define the hyperparameter grid for LinfPGD\n",
        "rel_stepsize_grid = [0.527]  # Relative step sizes\n",
        "steps_grid = [20]  # Number of optimization steps\n",
        "epsilons_grid = [14/255]  # Epsilon values to keep fixed\n",
        "\n",
        "# Combine all hyperparameters into a grid\n",
        "grid = list(itertools.product(rel_stepsize_grid, steps_grid, epsilons_grid ))\n",
        "\n",
        "# Function to run the attack with the given hyperparameters\n",
        "def run_attack(model_fb, x_test, y_test, rel_stepsize, steps, epsilons):\n",
        "    return fb.attacks.LinfPGD(rel_stepsize=rel_stepsize, steps=steps)(model_fb, x_test, y_test, epsilons=epsilons)\n",
        "\n",
        "# Iterate through the hyperparameter grid\n",
        "results = []\n",
        "for params in grid:\n",
        "    rel_stepsize, steps,epsilons_grid  = params\n",
        "    print(f\"Running attack with params: rel_stepsize={rel_stepsize}, steps={steps}, epsilon:{epsilons_grid}\")\n",
        "\n",
        "    # Run the attack with current parameters\n",
        "    _, advs, success = run_attack(model_fb, x_test, y_test,\n",
        "                                  rel_stepsize=rel_stepsize,\n",
        "                                  steps=steps,\n",
        "                                  epsilons=epsilons_grid)\n",
        "\n",
        "    # Evaluate based on your custom scoring system (update this according to your project)\n",
        "    score = 1 - success.float().mean()\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        'rel_stepsize': rel_stepsize,\n",
        "        'steps': steps,\n",
        "        'score': score,\n",
        "        'epsilon': epsilons_grid\n",
        "    })\n",
        "    print(f\"Score: {score}\")\n",
        "\n",
        "# After completing the grid search, find the best set of parameters based on the score\n",
        "best_result = max(results, key=lambda x: x['score'])\n",
        "print(f\"Best result: {best_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG1iCNLbpto4"
      },
      "source": [
        "# **Using Grid Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "id": "wNbYtpKAJX56",
        "outputId": "1502fe53-e216-4e20-9754-1ce5140cce2b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-10-17 02:54:20,242] A new study created in memory with name: no-name-563dc5c6-31c9-4c47-b130-474fccd04633\n",
            "[I 2024-10-17 02:54:28,417] Trial 0 finished with value: 0.9319999814033508 and parameters: {'binary_search_steps': 7, 'steps': 20, 'stepsize': 0.04302324573732417, 'confidence': 0.08915416145722999, 'initial_const': 0.006035334017021206}. Best is trial 0 with value: 0.9319999814033508.\n",
            "[W 2024-10-17 02:54:31,619] Trial 1 failed with parameters: {'binary_search_steps': 7, 'steps': 20, 'stepsize': 0.03563884709681438, 'confidence': 0.04187849545287936, 'initial_const': 0.0030783855748649745} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-14-d018125f52d9>\", line 16, in objective\n",
            "    _, advs, success = fb.attacks.L2CarliniWagnerAttack(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/foolbox/attacks/base.py\", line 416, in __call__\n",
            "    xp = self.run(model, x, criterion, early_stop=early_stop, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/foolbox/attacks/carlini_wagner.py\", line 175, in run\n",
            "    if not (loss <= 0.9999 * loss_at_previous_check):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/eagerpy/tensor/base.py\", line 50, in __bool__\n",
            "    return bool(self.raw)\n",
            "KeyboardInterrupt\n",
            "[W 2024-10-17 02:54:31,620] Trial 1 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d018125f52d9>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Create an Optuna study and run the optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust n_trials as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Get the best result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-d018125f52d9>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Run the attack with the suggested parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     _, advs, success = fb.attacks.L2CarliniWagnerAttack(\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mbinary_search_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary_search_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/foolbox/attacks/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# run the actual attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mxpcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/foolbox/attacks/carlini_wagner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_early\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                     \u001b[0;31m# after each tenth of the overall steps, check progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.9999\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_at_previous_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                         \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# stop Adam if there has been no progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0mloss_at_previous_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/eagerpy/tensor/base.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import foolbox as fb\n",
        "\n",
        "# Define the objective function for Bayesian optimization\n",
        "def objective(trial):\n",
        "    # Use Optuna to suggest values for hyperparameters\n",
        "    binary_search_steps = trial.suggest_int('binary_search_steps', 7, 9)\n",
        "    steps = trial.suggest_categorical('steps', [20])\n",
        "    stepsize = trial.suggest_float('stepsize', 0.01, 0.05)\n",
        "    confidence = trial.suggest_float('confidence', 0, 0.1)\n",
        "    initial_const = trial.suggest_float('initial_const', 0.001, 0.01)\n",
        "\n",
        "    epsilons = [8 / 255]  # Keep epsilon fixed for now\n",
        "\n",
        "    # Run the attack with the suggested parameters\n",
        "    _, advs, success = fb.attacks.L2CarliniWagnerAttack(\n",
        "        binary_search_steps=binary_search_steps,\n",
        "        steps=steps,\n",
        "        stepsize=stepsize,\n",
        "        confidence=confidence,\n",
        "        initial_const=initial_const\n",
        "    )(model_fb, x_test, y_test, epsilons=epsilons)\n",
        "\n",
        "    # Custom scoring system (update according to your project needs)\n",
        "    score = 1 - success.float().mean()\n",
        "\n",
        "    # Return the score (Optuna will try to maximize this)\n",
        "    return score\n",
        "\n",
        "# Create an Optuna study and run the optimization\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)  # Adjust n_trials as needed\n",
        "\n",
        "# Get the best result\n",
        "best_result = study.best_trial\n",
        "print(f\"Best hyperparameters: {best_result.params}\")\n",
        "print(f\"Best score: {best_result.value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxeMMZ-gRzzR"
      },
      "source": [
        "### Let's compare the accuracies before and after perturbation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY92YmusJee2",
        "outputId": "6ffb60e3-310b-4d40-8006-b22532abf395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Robust accuracy: 0.0%\n",
            "0.941\n"
          ]
        }
      ],
      "source": [
        "print('Robust accuracy: {:.1%}'.format(1 - success.float().mean()))\n",
        "print(clean_accuracy(model, x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAGYD88bR73n"
      },
      "source": [
        "### Let's explore how our perturbations look!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-wa0RC_OBxs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Pass the perturbed images through the model to get the predicted labels\n",
        "with torch.no_grad():  # No need to track gradients during inference\n",
        "    logits_adv = model(advs[0].to('cuda'))  # Get the logits for the adversarial examples\n",
        "\n",
        "# Get the predicted labels from the logits\n",
        "predicted_labels_adv = torch.argmax(logits_adv, dim=1)\n",
        "\n",
        "# Find which examples were misclassified (where predicted label != true label)\n",
        "misclassified_indices = (predicted_labels_adv != y_test.to('cuda')).nonzero(as_tuple=True)[0]\n",
        "\n",
        "# Get the misclassified original and perturbed images, true labels, and incorrect labels\n",
        "misclassified_images = advs[0][misclassified_indices]\n",
        "misclassified_original_images = x_test.to('cuda')[misclassified_indices]\n",
        "misclassified_predicted_labels = predicted_labels_adv[misclassified_indices]\n",
        "misclassified_true_labels = y_test.to('cuda')[misclassified_indices]\n",
        "\n",
        "# Choose a random subset of misclassified images to display\n",
        "num_images_to_show = min(10, len(misclassified_images))  # Limit to 10 images for display\n",
        "random_indices = random.sample(range(len(misclassified_images)), num_images_to_show)\n",
        "\n",
        "# Class names (assuming CIFAR-10)\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Plot the original and misclassified perturbed images side by side\n",
        "plt.figure(figsize=(25, 5))\n",
        "for i, idx in enumerate(random_indices):\n",
        "    # Original image\n",
        "    original_image = misclassified_original_images[idx]\n",
        "    true_label = misclassified_true_labels[idx].item()\n",
        "\n",
        "    # Perturbed image\n",
        "    perturbed_image = misclassified_images[idx]\n",
        "    incorrect_label = misclassified_predicted_labels[idx].item()\n",
        "\n",
        "    # Convert images from tensor to numpy and transpose from (C, H, W) to (H, W, C)\n",
        "    original_img = original_image.permute(1, 2, 0).cpu().numpy()\n",
        "    perturbed_img = perturbed_image.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    # Plot original image\n",
        "    plt.subplot(2, num_images_to_show, i+1)\n",
        "    plt.imshow(original_img, interpolation='none')\n",
        "    plt.title(f\"Original: {class_names[true_label]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Plot perturbed (misclassified) image\n",
        "    plt.subplot(2, num_images_to_show, num_images_to_show + i + 1)\n",
        "    plt.imshow(perturbed_img, interpolation='none')\n",
        "    plt.title(f\"Perturbed: {class_names[incorrect_label]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgEqeBozSBvG"
      },
      "source": [
        "### Finally!\n",
        "\n",
        "* Let's save our perturbed samples in a folder called 'challenge' and submit them for the evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "i3gPVt_AOMb4"
      },
      "outputs": [],
      "source": [
        "# Create the 'challenge' directory if it doesn't exist\n",
        "os.makedirs('challenge', exist_ok=True)\n",
        "\n",
        "# Path to save the adversarial examples\n",
        "file_path = os.path.join('challenge', 'advs.pkl')\n",
        "\n",
        "# Save the 'advs' object\n",
        "with open(file_path, 'wb') as f:\n",
        "    pickle.dump(advs, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVNnjEZnSQ4b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
