{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElyasYassin/DecoyChallenge/blob/main/OptimizedLinfPGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set UP\n",
        "* Robustbench: this library is used for loading robust classifer, For more information visit: https://github.com/RobustBench/robustbench\n",
        "\n",
        "* foolbox: this library is used for adversarial example generation. For more information visit: https://github.com/bethgelab/foolbox"
      ],
      "metadata": {
        "id": "U2iDhUE0OQJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/RobustBench/robustbench.git # library for loading robust classifer\n",
        "!pip install -q foolbox # library for adversarial example generation\n",
        "!pip install timm==1.0.9"
      ],
      "metadata": {
        "id": "qPZQUpV4J-oL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "print(timm.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSA6ejlGe6Px",
        "outputId": "548906fb-8a69-4291-ae75-1798efd392b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from robustbench.utils import clean_accuracy\n",
        "from robustbench.utils import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import unique\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import os"
      ],
      "metadata": {
        "id": "V-XG3NmQI8aF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and preprocess the data:\n",
        "\n",
        "* We will use 1000 test examples from the cifar 10 dataset. These images are new to the model as it hasn't seen them in the training phase. We want to fool the model on its predictions for new images!"
      ],
      "metadata": {
        "id": "QiKA1t-QOzlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "output_file = 'cifar10.pt'\n",
        "file_id = \"1A5gQCE0bHZhBlfcLQ2fFP5UygpgVkdAX\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_file)"
      ],
      "metadata": {
        "id": "XFuubfX3G6Ul",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "41a53041-24cc-44c2-ff93-680765cfb78a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A5gQCE0bHZhBlfcLQ2fFP5UygpgVkdAX\n",
            "To: /content/cifar10.pt\n",
            "100%|██████████| 12.3M/12.3M [00:00<00:00, 22.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cifar10.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_data = torch.load('cifar10.pt')"
      ],
      "metadata": {
        "id": "2HPgPWYFJLHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acfff3eb-e861-4a99-de1a-230094120142"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-b0f49031be72>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  cifar_data = torch.load('cifar10.pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the images and labels tensors\n",
        "x_test = cifar_data['images'] / 255.0\n",
        "y_test = cifar_data['labels']\n",
        "\n",
        "print(unique(y_test, return_counts=True))"
      ],
      "metadata": {
        "id": "7D32wiSfHJHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e4304a-2bcf-4b7f-8a9a-b8938ecc4ed3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([100, 100, 100, 100, 100, 100, 100, 100, 100, 100]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test.shape, y_test.shape)\n",
        "print(torch.max(x_test), torch.min(x_test))"
      ],
      "metadata": {
        "id": "3Xp3JY6QJPuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d637182-f92a-4621-abff-dd8316fb83e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 3, 32, 32]) torch.Size([1000])\n",
            "tensor(1.) tensor(0.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the robust model\n",
        "\n",
        "* IMPORTANT: You shouldn't change this part of the code as your final generated examples will be evaluated how successful you are at fooling this model!"
      ],
      "metadata": {
        "id": "SiHHpdfePSr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import robustbench.utils\n",
        "model = load_model(model_name='Kireev2021Effectiveness_RLATAugMix', dataset='cifar10', threat_model='corruptions')"
      ],
      "metadata": {
        "id": "MZEph6jWJQKz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a34a1d-bbee-49eb-9387-d7ee59293137"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading models/cifar10/corruptions/Kireev2021Effectiveness_RLATAugMix.pt (gdrive_id=19HNTdqJiuNyqFqIarPejniJEjZ3RQ_nj).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=19HNTdqJiuNyqFqIarPejniJEjZ3RQ_nj\n",
            "From (redirected): https://drive.google.com/uc?id=19HNTdqJiuNyqFqIarPejniJEjZ3RQ_nj&confirm=t&uuid=eb31fde4-e60d-4ffe-ae44-88266743779e\n",
            "To: /content/models/cifar10/corruptions/Kireev2021Effectiveness_RLATAugMix.pt\n",
            "100%|██████████| 89.5M/89.5M [00:02<00:00, 30.5MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/robustbench/utils.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU Utilization\n",
        "\n",
        "* For shorter running time, let's utilize GPU!"
      ],
      "metadata": {
        "id": "aUF3TMgfPzgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available and set the device accordingly\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "model = model.to(device)\n",
        "x_test = x_test.to(device)\n",
        "y_test = y_test.to(device)"
      ],
      "metadata": {
        "id": "0FTfa9zuJQH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9967d5-d7e6-4336-b8b2-f9f661d5f2c1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adversarial Example Generation -- Adversarial Perturbation\n",
        "\n",
        "* Here for a baseline, we use the PGD algorithm from foolbox library. This is the most important part of the challenge. What algorithm is gonna work best?\n",
        "\n",
        "* There are many algorithms and many other adversarial example generation algorithms. Don't forget to check out other libraries!\n",
        "\n",
        "  * One other very popular library among many others is Adversarial Robustness Toolbox (ART)!\n",
        "  * There are many more algorithms out there, your task is to find the ones that works best based on our evaluation metrics."
      ],
      "metadata": {
        "id": "czWsx4ePQIkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fb = fb.PyTorchModel(model, bounds=(0, 1))"
      ],
      "metadata": {
        "id": "g0nS_MDuPxri"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, advs, success = fb.attacks.LinfPGD(rel_stepsize=0.527, steps=10)(model_fb, x_test, y_test, epsilons=[8/255])\n"
      ],
      "metadata": {
        "id": "eWP3A6Cqm7Xe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import foolbox as fb\n",
        "\n",
        "# Define the hyperparameter grid for LinfPGD\n",
        "rel_stepsize_grid = [0.527]  # Relative step sizes\n",
        "steps_grid = [250, 300, ...]  # Number of optimization steps\n",
        "epsilons_grid = [14/255]  # Epsilon values to keep fixed\n",
        "\n",
        "# Combine all hyperparameters into a grid\n",
        "grid = list(itertools.product(rel_stepsize_grid, steps_grid, epsilons_grid ))\n",
        "\n",
        "# Function to run the attack with the given hyperparameters\n",
        "def run_attack(model_fb, x_test, y_test, rel_stepsize, steps, epsilons):\n",
        "    return fb.attacks.LinfPGD(rel_stepsize=rel_stepsize, steps=steps)(model_fb, x_test, y_test, epsilons=epsilons)\n",
        "\n",
        "# Iterate through the hyperparameter grid\n",
        "results = []\n",
        "for params in grid:\n",
        "    rel_stepsize, steps,epsilons_grid  = params\n",
        "    print(f\"Running attack with params: rel_stepsize={rel_stepsize}, steps={steps}, epsilon:{epsilons_grid}\")\n",
        "\n",
        "    # Run the attack with current parameters\n",
        "    _, advs, success = run_attack(model_fb, x_test, y_test,\n",
        "                                  rel_stepsize=rel_stepsize,\n",
        "                                  steps=steps,\n",
        "                                  epsilons=epsilons_grid)\n",
        "\n",
        "    # Evaluate based on your custom scoring system (update this according to your project)\n",
        "    score = 1 - success.float().mean()\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        'rel_stepsize': rel_stepsize,\n",
        "        'steps': steps,\n",
        "        'score': score,\n",
        "        'epsilon': epsilons_grid\n",
        "    })\n",
        "    print(f\"Score: {score}\")\n",
        "\n",
        "# After completing the grid search, find the best set of parameters based on the score\n",
        "best_result = max(results, key=lambda x: x['score'])\n",
        "print(f\"Best result: {best_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du34tCWUrhEo",
        "outputId": "fb5f8667-44c0-4b07-ac2c-97249f1b17e4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running attack with params: rel_stepsize=0.527, steps=250, epsilon:0.054901960784313725\n",
            "Score: 0.0\n",
            "Best result: {'rel_stepsize': 0.527, 'steps': 250, 'score': tensor(0., device='cuda:0'), 'epsilon': 0.054901960784313725}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using Grid Search**"
      ],
      "metadata": {
        "id": "bG1iCNLbpto4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nifM2x_GqWzY",
        "outputId": "4eda5889-d355-4b96-e37b-9d37eed27e32"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.1)\n",
            "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.3 colorlog-6.8.2 optuna-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import foolbox as fb\n",
        "\n",
        "# Define the objective function for Bayesian optimization\n",
        "def objective(trial):\n",
        "    # Use Optuna to suggest values for hyperparameters\n",
        "    binary_search_steps = trial.suggest_int('binary_search_steps', 7, 9)\n",
        "    steps = trial.suggest_categorical('steps', [20])\n",
        "    stepsize = trial.suggest_float('stepsize', 0.01, 0.05)\n",
        "    confidence = trial.suggest_float('confidence', 0, 0.1)\n",
        "    initial_const = trial.suggest_float('initial_const', 0.001, 0.01)\n",
        "\n",
        "    epsilons = [8 / 255]  # Keep epsilon fixed for now\n",
        "\n",
        "    # Run the attack with the suggested parameters\n",
        "    _, advs, success = fb.attacks.L2CarliniWagnerAttack(\n",
        "        binary_search_steps=binary_search_steps,\n",
        "        steps=steps,\n",
        "        stepsize=stepsize,\n",
        "        confidence=confidence,\n",
        "        initial_const=initial_const\n",
        "    )(model_fb, x_test, y_test, epsilons=epsilons)\n",
        "\n",
        "    # Custom scoring system (update according to your project needs)\n",
        "    score = 1 - success.float().mean()\n",
        "\n",
        "    # Return the score (Optuna will try to maximize this)\n",
        "    return score\n",
        "\n",
        "# Create an Optuna study and run the optimization\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)  # Adjust n_trials as needed\n",
        "\n",
        "# Get the best result\n",
        "best_result = study.best_trial\n",
        "print(f\"Best hyperparameters: {best_result.params}\")\n",
        "print(f\"Best score: {best_result.value}\")"
      ],
      "metadata": {
        "id": "wNbYtpKAJX56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "outputId": "1502fe53-e216-4e20-9754-1ce5140cce2b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-10-17 02:54:20,242] A new study created in memory with name: no-name-563dc5c6-31c9-4c47-b130-474fccd04633\n",
            "[I 2024-10-17 02:54:28,417] Trial 0 finished with value: 0.9319999814033508 and parameters: {'binary_search_steps': 7, 'steps': 20, 'stepsize': 0.04302324573732417, 'confidence': 0.08915416145722999, 'initial_const': 0.006035334017021206}. Best is trial 0 with value: 0.9319999814033508.\n",
            "[W 2024-10-17 02:54:31,619] Trial 1 failed with parameters: {'binary_search_steps': 7, 'steps': 20, 'stepsize': 0.03563884709681438, 'confidence': 0.04187849545287936, 'initial_const': 0.0030783855748649745} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-14-d018125f52d9>\", line 16, in objective\n",
            "    _, advs, success = fb.attacks.L2CarliniWagnerAttack(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/foolbox/attacks/base.py\", line 416, in __call__\n",
            "    xp = self.run(model, x, criterion, early_stop=early_stop, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/foolbox/attacks/carlini_wagner.py\", line 175, in run\n",
            "    if not (loss <= 0.9999 * loss_at_previous_check):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/eagerpy/tensor/base.py\", line 50, in __bool__\n",
            "    return bool(self.raw)\n",
            "KeyboardInterrupt\n",
            "[W 2024-10-17 02:54:31,620] Trial 1 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d018125f52d9>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Create an Optuna study and run the optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust n_trials as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Get the best result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-d018125f52d9>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Run the attack with the suggested parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     _, advs, success = fb.attacks.L2CarliniWagnerAttack(\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mbinary_search_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary_search_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/foolbox/attacks/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# run the actual attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mxpcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/foolbox/attacks/carlini_wagner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_early\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                     \u001b[0;31m# after each tenth of the overall steps, check progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.9999\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_at_previous_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                         \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# stop Adam if there has been no progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0mloss_at_previous_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/eagerpy/tensor/base.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's compare the accuracies before and after perturbation!"
      ],
      "metadata": {
        "id": "wxeMMZ-gRzzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Robust accuracy: {:.1%}'.format(1 - success.float().mean()))\n",
        "print(clean_accuracy(model, x_test, y_test))"
      ],
      "metadata": {
        "id": "OY92YmusJee2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ffb60e3-310b-4d40-8006-b22532abf395"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Robust accuracy: 0.0%\n",
            "0.941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's explore how our perturbations look!"
      ],
      "metadata": {
        "id": "nAGYD88bR73n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Pass the perturbed images through the model to get the predicted labels\n",
        "with torch.no_grad():  # No need to track gradients during inference\n",
        "    logits_adv = model(advs[0].to('cuda'))  # Get the logits for the adversarial examples\n",
        "\n",
        "# Get the predicted labels from the logits\n",
        "predicted_labels_adv = torch.argmax(logits_adv, dim=1)\n",
        "\n",
        "# Find which examples were misclassified (where predicted label != true label)\n",
        "misclassified_indices = (predicted_labels_adv != y_test.to('cuda')).nonzero(as_tuple=True)[0]\n",
        "\n",
        "# Get the misclassified original and perturbed images, true labels, and incorrect labels\n",
        "misclassified_images = advs[0][misclassified_indices]\n",
        "misclassified_original_images = x_test.to('cuda')[misclassified_indices]\n",
        "misclassified_predicted_labels = predicted_labels_adv[misclassified_indices]\n",
        "misclassified_true_labels = y_test.to('cuda')[misclassified_indices]\n",
        "\n",
        "# Choose a random subset of misclassified images to display\n",
        "num_images_to_show = min(10, len(misclassified_images))  # Limit to 10 images for display\n",
        "random_indices = random.sample(range(len(misclassified_images)), num_images_to_show)\n",
        "\n",
        "# Class names (assuming CIFAR-10)\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Plot the original and misclassified perturbed images side by side\n",
        "plt.figure(figsize=(25, 5))\n",
        "for i, idx in enumerate(random_indices):\n",
        "    # Original image\n",
        "    original_image = misclassified_original_images[idx]\n",
        "    true_label = misclassified_true_labels[idx].item()\n",
        "\n",
        "    # Perturbed image\n",
        "    perturbed_image = misclassified_images[idx]\n",
        "    incorrect_label = misclassified_predicted_labels[idx].item()\n",
        "\n",
        "    # Convert images from tensor to numpy and transpose from (C, H, W) to (H, W, C)\n",
        "    original_img = original_image.permute(1, 2, 0).cpu().numpy()\n",
        "    perturbed_img = perturbed_image.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    # Plot original image\n",
        "    plt.subplot(2, num_images_to_show, i+1)\n",
        "    plt.imshow(original_img, interpolation='none')\n",
        "    plt.title(f\"Original: {class_names[true_label]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Plot perturbed (misclassified) image\n",
        "    plt.subplot(2, num_images_to_show, num_images_to_show + i + 1)\n",
        "    plt.imshow(perturbed_img, interpolation='none')\n",
        "    plt.title(f\"Perturbed: {class_names[incorrect_label]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "q-wa0RC_OBxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finally!\n",
        "\n",
        "* Let's save our perturbed samples in a folder called 'challenge' and submit them for the evaluation."
      ],
      "metadata": {
        "id": "vgEqeBozSBvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the 'challenge' directory if it doesn't exist\n",
        "os.makedirs('challenge', exist_ok=True)\n",
        "\n",
        "# Path to save the adversarial examples\n",
        "file_path = os.path.join('challenge', 'advs.pkl')\n",
        "\n",
        "# Save the 'advs' object\n",
        "with open(file_path, 'wb') as f:\n",
        "    pickle.dump(advs, f)"
      ],
      "metadata": {
        "id": "i3gPVt_AOMb4"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eVNnjEZnSQ4b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}